# ğŸ“˜ EduGenie: Project Development Log (Chronological)

---

## ğŸ—“ï¸ Day 1: Project Setup, Raw Data, and Initial Chunking
**ğŸ¯ Objective:** Set up the foundational structure, collect source material, and preprocess data.

### âœ… Tasks Completed:
1. **Project Structure Initialized:**
   - Created directories: `data/raw`, `data/processed`, `scripts/`, `embeddings/`, `rag/`, etc.

2. **Downloaded NCERT PDFs:**
   - Stored: `science_class_7.pdf` to `science_class_10.pdf` in `data/raw`.

3. **Semantic Chunking Implemented:**
   - Wrote `semantic_chunker.py` to tokenize and structure content using NLTK.

4. **NLTK Tokenizer Issue:**
   - **Issue:** `LookupError: Resource punkt not found.`
   - **Fix:** Used `nltk.download()` to open the downloader UI and install all needed packages.

5. **Broken PDF File Issue:**
   - **Issue:** `MuPDF error: zlib error: incorrect header check` (Class 8).
   - **Fix:** Replaced corrupted file with a working version.

### âœ… Outcome:
- ğŸŸ¢ Project structure solidified.
- ğŸŸ¢ All NCERT PDFs successfully parsed into structured chunks.

---

## ğŸ—“ï¸ Day 2: Embeddings, Retrieval, and Generation Pipeline
**ğŸ¯ Objective:** Build the complete RAG pipeline with embedding, retrieval, and answer generation.

### âœ… Embedding Stage:
- Created `embedder.py` using `sentence-transformers`.
- Created `vector_store.py` using FAISS to store vectors.
- Wrote `test_embedder.py`.

**Issues & Fixes:**
- **KeyError:** `chunk["text"]` â†’ **Fix:** Used correct field `chunk["content"]`.
- **Module Import Error:** Fixed by appending project root to `sys.path`.

âœ… Result: FAISS index built with 893 embedded chunks.

---

### âœ… Retrieval Stage:
- Developed `retriever.py` with `Retriever` class.
- Script `test_retriever.py` used to fetch top-k chunks for queries.

**Issue:** `retrieve_top_chunks` not recognized.  
**Fix:** Used method via instantiated class (`Retriever().retrieve()`).

âœ… Result: Relevant chunks successfully retrieved for user queries.

---

### âœ… Generation Stage:
- Created `generator.py` to generate answers using **Groq API with LLaMA 3**.
- Wrote `test_generator.py`.

**Issues & Fixes:**
1. **Preview Error:** `KeyError` on printing chunk.  
   - **Fix:** Extracted `chunk["content"][:200]`.
2. **Join Error:** `TypeError: expected str, got dict`.  
   - **Fix:** Extracted just the `"content"` field before joining.
3. **Unstructured/Repetitive Answer:**  
   - **Fix:** Redesigned the prompt to guide the model in:
     - Structuring content.
     - Avoiding redundancy.
     - Maintaining semantic and chronological clarity.

âœ… Result: Final output answers are now well-structured, coherent, and accurate.

---

## âœ… Current Status
- âœ… Working RAG pipeline from chunking â embedding â retrieval â generation.
- âœ… Integrated with Groq (LLaMA 3).
- âœ… Tuned prompts improve output quality significantly.
- âœ… Tested with multiple questions and content sources.

---


## ğŸ—“ï¸ Day 3 â€“ EduGenie RAG UI & Chatbot Integration

**ğŸ¯ Objective:** Design and implement a functional, interactive, and extensible Streamlit-based RAG chatbot UI for EduGenie, targeting UPSC aspirants using NCERT-based science content.

### ğŸ“Œ Steps Taken & Progress Summary

| Step | Description | Objective | Issues Faced | Solution/Outcome |
|------|-------------|-----------|--------------|------------------|
| 1ï¸âƒ£ | Planning Streamlit App UI | Build a chat-like interactive app for RAG-based Q&A | â€“ | Decided to start from a prototype UI and scale gradually |
| 2ï¸âƒ£ | Confirmed Repo Structure | Ensure the app follows the correct repo layout | Initially unsure of structure | Referred to repo diagram to realign |
| 3ï¸âƒ£ | Prototype UI Created | Initial `streamlit_app.py` created with chat input and response generation | â€“ | Functional base UI working with `Retriever` + `generate_answer()` |
| 4ï¸âƒ£ | Deprecated API Issue | `streamlit.experimental_rerun()` caused error | Streamlit version removed it | Removed the line; app worked fine |
| 5ï¸âƒ£ | Identified Missing Components | Listed out `utils.py`, `config.yaml`, `test_pipeline.py`, `ingest_content.py` | â€“ | Created a clear plan for each |
| 6ï¸âƒ£ | Built `utils.py` | Moved formatting and chat logic out of UI file | â€“ | Functions modularized: display, formatting, appending |
| 7ï¸âƒ£ | Refactored Streamlit App | Replaced logic with `utils.py` function calls | ImportError for `app.utils` | Fixed by importing as `from utils import ...` |
| 8ï¸âƒ£ | Verified Full Chat Flow | Tested user Q&A flow end-to-end | â€“ | Chat history and responses worked flawlessly |
| 9ï¸âƒ£ | Runtime Warning (Torch) | `torch.classes` warning triggered by Streamlit reload | From internal watcher system | Ignored safely, no crash |
| ğŸ”Ÿ | Improved App Title | Wanted a UPSC-focused title | Explored options | Finalized: **EduGenie â€“ Your NCERT Science AI Assistant** |

### ğŸ“¦ Final Outcome

- âœ… Working chatbot UI (`streamlit.py`)
- âœ… Chat history retained across messages
- âœ… Answer and retrieved context formatted and shown
- âœ… UI logic moved to clean, reusable `utils.py`
- âœ… Title customized to reflect UPSC preparation context

### ğŸ§  Key Takeaways

- Chat interface now supports multi-turn Q&A
- Modular code is easier to scale and maintain
- UPSC-aligned branding is in place for user clarity

## ğŸ”œ Next Steps
- Evaluate answers automatically using ROUGE/BLEU.
- Expand to additional subjects or regional languages.
- Deploy to Hugging Face or Streamlit Cloud.

---
